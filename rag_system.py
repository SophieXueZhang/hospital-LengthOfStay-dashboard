#!/usr/bin/env python3
"""
RAGæ£€ç´¢ç³»ç»Ÿï¼šæ ¹æ®æ‚£è€…ç—‡çŠ¶æ£€ç´¢ç›¸å…³è®ºæ–‡
"""

import os
import sqlite3
import json
import openai
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class RAGSystem:
    def __init__(self, db_path='/Users/pc/Documents/cursor/ml_course/project/data/papers_rag.db'):
        self.db_path = db_path
        self.client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # åŒ»å­¦ç—‡çŠ¶å…³é”®è¯æ˜ å°„
        self.symptom_keywords = {
            'anemia': ['anemia', 'anemic', 'hemoglobin', 'hematocrit', 'iron deficiency', 'low blood count'],
            'pneumonia': ['pneumonia', 'lung infection', 'respiratory infection', 'chest infection'],
            'asthma': ['asthma', 'breathing problems', 'respiratory issues', 'airway obstruction'],
            'depression': ['depression', 'depressive', 'mental health', 'psychiatric', 'mood disorder'],
            'anxiety': ['anxiety', 'anxious', 'stress', 'panic', 'worry'],
            'diabetes': ['diabetes', 'diabetic', 'blood sugar', 'glucose', 'insulin'],
            'hypertension': ['hypertension', 'high blood pressure', 'blood pressure'],
            'heart disease': ['heart disease', 'cardiac', 'cardiovascular', 'heart failure'],
            'kidney disease': ['kidney disease', 'renal', 'nephrology', 'dialysis'],
            'substance abuse': ['substance abuse', 'drug abuse', 'addiction', 'substance use disorder']
        }
    
    def get_embedding(self, text):
        """è·å–æ–‡æœ¬çš„embedding"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-ada-002",
                input=text
            )
            return np.array(response.data[0].embedding)
        except Exception as e:
            print(f"è·å–embeddingå¤±è´¥: {e}")
            return None
    
    def extract_symptoms_from_patient(self, patient_data):
        """ä»æ‚£è€…æ•°æ®ä¸­æå–ç—‡çŠ¶å…³é”®è¯å’Œè¯Šæ–­ä¾æ®"""
        symptoms = []
        diagnostic_info = []
        
        # æ£€æŸ¥å„ç§åŒ»å­¦æŒ‡æ ‡ - ä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼
        # ä¸¥é‡è´«è¡€ï¼šè¡€ç»†èƒæ¯”å®¹ < 8
        if patient_data.get('hematocrit', 0) < 8:
            symptoms.append('anemia')
            hct_value = patient_data.get('hematocrit', 0)
            diagnostic_info.append(f"ä¸¥é‡è´«è¡€ (è¡€ç»†èƒæ¯”å®¹: {hct_value:.1f}g/dL, æ­£å¸¸å€¼: 12-16g/dL)")
        
        # æ£€æŸ¥å…·ä½“çš„ç–¾ç—…æ ‡å¿—ä½
        if patient_data.get('irondef', 0) == 1:
            symptoms.append('anemia')
            diagnostic_info.append("ç¼ºé“æ€§è´«è¡€ (é“ç¼ºä¹ç—‡æŒ‡æ ‡é˜³æ€§)")
            
        if patient_data.get('hemo', 0) == 1:
            symptoms.append('anemia')
            diagnostic_info.append("è´«è¡€ (è¡€çº¢è›‹ç™½å¼‚å¸¸æŒ‡æ ‡é˜³æ€§)")
            
        if patient_data.get('asthma', 0) == 1:
            symptoms.append('asthma')
            respiration = patient_data.get('respiration', 0)
            neutrophils = patient_data.get('neutrophils', 0)
            lab_findings = []
            if respiration > 20:
                lab_findings.append(f"å‘¼å¸é¢‘ç‡åé«˜: {respiration}/min (æ­£å¸¸: 12-20)")
            if neutrophils > 70:
                lab_findings.append(f"ä¸­æ€§ç²’ç»†èƒåé«˜: {neutrophils:.1f}% (æ­£å¸¸: 40-70%)")
            
            if lab_findings:
                diagnostic_info.append(f"å“®å–˜ (è¯Šæ–­æ ‡å¿—é˜³æ€§, {'; '.join(lab_findings)})")
            else:
                diagnostic_info.append("å“®å–˜ (å“®å–˜è¯Šæ–­æ ‡å¿—é˜³æ€§)")
            
        if patient_data.get('pneum', 0) == 1:
            symptoms.append('pneumonia')
            respiration = patient_data.get('respiration', 0)
            neutrophils = patient_data.get('neutrophils', 0)
            lab_findings = []
            if respiration > 20:
                lab_findings.append(f"å‘¼å¸é¢‘ç‡åé«˜: {respiration}/min (æ­£å¸¸: 12-20)")
            if neutrophils > 70:
                lab_findings.append(f"ä¸­æ€§ç²’ç»†èƒåé«˜: {neutrophils:.1f}% (æ­£å¸¸: 40-70%)")
            
            if lab_findings:
                diagnostic_info.append(f"è‚ºç‚ (è¯Šæ–­æ ‡å¿—é˜³æ€§, {'; '.join(lab_findings)})")
            else:
                diagnostic_info.append("è‚ºç‚ (è‚ºç‚è¯Šæ–­æ ‡å¿—é˜³æ€§)")
            
        if patient_data.get('depress', 0) == 1:
            symptoms.append('depression')
            diagnostic_info.append("æŠ‘éƒç—‡ (è¯Šæ–­æ ‡å¿—é˜³æ€§)")
            
        if patient_data.get('psychologicaldisordermajor', 0) == 1:
            symptoms.append('depression')
            diagnostic_info.append("é‡æ€§å¿ƒç†éšœç¢ (è¯Šæ–­æ ‡å¿—é˜³æ€§)")
            
        if patient_data.get('substancedependence', 0) == 1:
            symptoms.append('substance abuse')
            # ç‰©è´¨ä¾èµ–å¯èƒ½å¯¼è‡´è¥å…»ä¸è‰¯å’Œç”µè§£è´¨ç´Šä¹±ï¼Œè¿™äº›æ˜¯åˆç†çš„å…³è”
            sodium = patient_data.get('sodium', 0)
            if sodium < 135:
                diagnostic_info.append(f"ç‰©è´¨ä¾èµ– (è¯Šæ–­æ ‡å¿—é˜³æ€§, å¯èƒ½ä¼´æœ‰ç”µè§£è´¨ç´Šä¹±: è¡€é’  {sodium:.1f} mEq/L, æ­£å¸¸: 135-145)")
            else:
                diagnostic_info.append("ç‰©è´¨ä¾èµ– (è¯Šæ–­æ ‡å¿—é˜³æ€§)")
            
        if patient_data.get('dialysisrenalendstage', 0) == 1:
            symptoms.append('kidney disease')
            creatinine = patient_data.get('creatinine', 0)
            bloodureanitro = patient_data.get('bloodureanitro', 0)
            lab_findings = []
            if creatinine > 1.2:
                lab_findings.append(f"è‚Œé…åé«˜: {creatinine:.2f} mg/dL (æ­£å¸¸: 0.6-1.2)")
            if bloodureanitro > 25:
                lab_findings.append(f"è¡€å°¿ç´ æ°®åé«˜: {bloodureanitro:.1f} mg/dL (æ­£å¸¸: 7-25)")
            
            if lab_findings:
                diagnostic_info.append(f"ç»ˆæœ«æœŸè‚¾ç—… (é€ææ²»ç–—æ ‡å¿—é˜³æ€§, {'; '.join(lab_findings)})")
            else:
                diagnostic_info.append("ç»ˆæœ«æœŸè‚¾ç—… (é€ææ²»ç–—æ ‡å¿—é˜³æ€§)")
        
        # æ£€æŸ¥è¯Šæ–­ä»£ç æˆ–å…¶ä»–å­—æ®µä¸­çš„ç—‡çŠ¶
        diagnosis = str(patient_data.get('diagnosis', '')).lower()
        for symptom, keywords in self.symptom_keywords.items():
            for keyword in keywords:
                if keyword in diagnosis:
                    symptoms.append(symptom)
                    diagnostic_info.append(f"{symptom.title()} (è¯Šæ–­ä»£ç åŒ…å«: {keyword})")
                    break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šç—‡çŠ¶ï¼Œæ·»åŠ é€šç”¨åŒ»å­¦æœ¯è¯­
        if not symptoms:
            symptoms = ['length of stay', 'hospital admission', 'medical care']
        
        return list(set(symptoms)), diagnostic_info  # å»é‡ï¼Œè¿”å›ç—‡çŠ¶å’Œè¯Šæ–­ä¾æ®
    
    def search_relevant_papers(self, query, top_k=3):
        """æœç´¢ç›¸å…³è®ºæ–‡"""
        try:
            # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.db_path):
                return []
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰æ•°æ®
            cursor.execute('SELECT COUNT(*) FROM chunks')
            count = cursor.fetchone()[0]
            if count == 0:
                conn.close()
                return []
            
            # è·å–æŸ¥è¯¢çš„embedding
            query_embedding = self.get_embedding(query)
            if query_embedding is None:
                conn.close()
                return []
            
            # è·å–æ‰€æœ‰chunkså’Œå®ƒä»¬çš„embeddings
            cursor.execute('''
                SELECT c.id, c.chunk_text, c.embedding, p.title, p.filename
                FROM chunks c
                JOIN papers p ON c.paper_id = p.id
                WHERE c.embedding IS NOT NULL
            ''')
            
            results = cursor.fetchall()
            conn.close()
            
            if not results:
                return []
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = []
            for result in results:
                chunk_id, chunk_text, embedding_json, title, filename = result
                try:
                    chunk_embedding = np.array(json.loads(embedding_json))
                    similarity = cosine_similarity([query_embedding], [chunk_embedding])[0][0]
                    similarities.append({
                        'chunk_id': chunk_id,
                        'chunk_text': chunk_text,
                        'title': title,
                        'filename': filename,
                        'similarity': similarity
                    })
                except Exception as e:
                    continue
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›top_kç»“æœ
            similarities.sort(key=lambda x: x['similarity'], reverse=True)
            return similarities[:top_k]
            
        except Exception as e:
            print(f"æœç´¢è®ºæ–‡å¤±è´¥: {e}")
            return []
    
    def get_rag_response_for_patient(self, patient_data, user_question=None):
        """ä¸ºæ‚£è€…ç”ŸæˆåŸºäºRAGçš„å›ç­”"""
        # æå–æ‚£è€…ç—‡çŠ¶å’Œè¯Šæ–­ä¾æ®
        symptoms, diagnostic_info = self.extract_symptoms_from_patient(patient_data)
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        if user_question:
            search_query = f"{user_question} {' '.join(symptoms)}"
        else:
            search_query = ' '.join(symptoms)
        
        # æœç´¢ç›¸å…³è®ºæ–‡ - å¢åŠ æ•°é‡ä»¥è·å–æ›´å¤šç›¸å…³æ–‡çŒ®
        relevant_papers = self.search_relevant_papers(search_query, top_k=10)
        
        if not relevant_papers:
            return None, [], diagnostic_info
        
        # è¿‡æ»¤é«˜ç›¸ä¼¼åº¦çš„è®ºæ–‡ï¼ˆ0.8ä»¥ä¸Šï¼‰å¹¶æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå»é‡ï¼‰
        context_texts = []
        paper_references = []
        seen_titles = set()
        high_quality_papers = []
        
        for paper in relevant_papers:
            if paper['similarity'] >= 0.8 and paper['title'] not in seen_titles:
                context_texts.append(f"ä»è®ºæ–‡ã€Š{paper['title']}ã€‹(ç›¸ä¼¼åº¦: {paper['similarity']:.3f}): {paper['chunk_text'][:800]}...")
                paper_references.append(paper['title'])
                seen_titles.add(paper['title'])
                high_quality_papers.append(paper)
        
        context = "\n\n".join(context_texts)
        
        # ç”Ÿæˆå›ç­”
        prompt = f"""åŸºäºä»¥ä¸‹åŒ»å­¦æ–‡çŒ®å†…å®¹ï¼Œå›ç­”å…³äºæ‚£è€…çš„é—®é¢˜ã€‚

æ‚£è€…ç—‡çŠ¶å…³é”®è¯: {', '.join(symptoms)}
è¯Šæ–­ä¾æ®: {'; '.join(diagnostic_info)}
ç”¨æˆ·é—®é¢˜: {user_question if user_question else 'è¯·æä¾›ç›¸å…³åŒ»å­¦ä¿¡æ¯'}

ç›¸å…³æ–‡çŒ®å†…å®¹:
{context}

è¯·åŸºäºä¸Šè¿°æ–‡çŒ®å†…å®¹ï¼Œæä¾›å…¨é¢è¯¦ç»†çš„åŒ»å­¦åˆ†æå’Œå»ºè®®ã€‚è¯·åŠ¡å¿…ï¼š
1. ç»¼åˆæ‰€æœ‰æä¾›çš„é«˜ç›¸ä¼¼åº¦æ–‡çŒ®å†…å®¹ï¼ˆç›¸ä¼¼åº¦â‰¥0.8ï¼‰
2. è¯¦ç»†åˆ†ææ¯ç¯‡ç›¸å…³è®ºæ–‡çš„æ ¸å¿ƒå‘ç°
3. å°†æ–‡çŒ®ç»“è®ºä¸æ‚£è€…çš„å…·ä½“ç—‡çŠ¶å’Œè¯Šæ–­ä¾æ®å…³è”
4. æä¾›å¾ªè¯åŒ»å­¦å»ºè®®å’Œæ²»ç–—æŒ‡å¯¼
5. ä¸è¦é™åˆ¶å›ç­”é•¿åº¦ï¼Œè¯·æä¾›å®Œæ•´è¯¦å°½çš„åˆ†æ

å¦‚æœæ–‡çŒ®å†…å®¹ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·è¯´æ˜éœ€è¦æ›´å¤šä¿¡æ¯ã€‚"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦åŠ©æ‰‹ï¼ŒåŸºäºæä¾›çš„æ–‡çŒ®å†…å®¹å›ç­”é—®é¢˜ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7
            )
            
            ai_response = response.choices[0].message.content
            
            # æ·»åŠ å‚è€ƒæ–‡çŒ®
            if paper_references:
                ai_response += f"\n\nğŸ“š å‚è€ƒæ–‡çŒ®:\n" + "\n".join([f"â€¢ {ref}" for ref in paper_references])
            
            return ai_response, relevant_papers, diagnostic_info
            
        except Exception as e:
            print(f"ç”ŸæˆRAGå›ç­”å¤±è´¥: {e}")
            return None, relevant_papers, diagnostic_info

# å…¨å±€RAGç³»ç»Ÿå®ä¾‹
rag_system = RAGSystem()